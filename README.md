# ans-playbook

......

Ответы на тестовые

1. Какие базовые метрики вы добавили бы в первую очередь (с точки зрения БД и ОС) для мониторинга состояния базы данных? Какие инструменты для сбора метрик будете использовать? Обоснуйте свой выбор

С точки зрения ОС:
Загрузка CPU, использование ОП, занятое пространство и очередь по дискам, состояние службы.
С точки зрения БД:
Подключения, транзакции, чекпоинты, мониторинг внутренних служб -  фоновая запись, автовакуум, попадение в кэш, размеры по базам, дэдлоки.
Являюсь сторонником централизованных средсв мониторинга, поэтому буду предполагать что метрики будут собираться для последующей отправки к примеру в Prometheus либо Zabbix.
В случае если кроме мониторинга БД необходимо мониторить всю остальную инфраструктуру компании, то использовал бы Zabbix, соответственно собирал бы через zabbix agent 2. Если предполагается только мониторинг баз, то скорее использовал бы Prometheus и для сбора соответсвенно использовал бы postgres_exporter как рекомендуемый https://prometheus.io/docs/instrumenting/exporters/. В случае использования иных средств для централизованного мониторинга предпочел бы сбор метрик средствами их агентов, если это возможно.

2. Какие порекомендуете настройки БД и/или схему хранения данных для OLAP нагрузки, где требуется обработка пользовательской истории торговли в виде агрегатных запросов (суммарная торговая активность пользователи за X время в разных измерениях).

Настроить упреждающее чтение и Huge Pages для Postgresql в ОС, а так же другие параметры в соответсвии с рекомендациями Postgresql и производителя ОС.
В соответсвии с параметрами железа:
Увеличить shared_buffers, temp_buffers, work_mem, effective_cache_size, параметры касающиеся параллельной обработки.
Настроить остальные параметры в соответсвии с данными мониторинга.
В зависимости от объемов данных, реализовать секционирование/шардирование к примеру по временной шкале.

3. Какие порекомендуете настройки БД и/или схему хранения данных для OLTP нагрузки вида процессинга платежных операций, где большой поток пользователей ежесекундно совершает инвестиционные операции на своем балансе и требуется высокая степень отклика от системы. С какими проблемами мы можем столкнуться при увеличении числа уникальных пользователей? Как будем решать эту задачу?

Увеличить wal-segsize, соответственно подстроить wal_buffers если необходимо.
Вынести pg_wal на отдельный носитель.
Поэкспериментировать с планировщиком ввода/вывода, а так же настроить другие параметры в соответсвии с рекомендациями Postgresql и производителя ОС.

Проверить что wal_compression включен
Увеличить checkpoint_timeout + min_wal_size  + max_wal_size
Провести эксперименты с commit_delay
В соответсвии с параметрами железа:
Выставить effective_io_concurrency
Настроить остальные параметры в соответсвии с данными мониторинга.

В случае большого колличества обращений и сильного увеличения потребления памяти, нагрузки на процессор  с постоянными переключениями контекста к примеру, и как следствие снижения производительности - использовать пул соединений с поддержкой транзакций, так же если пользователи у нас будут храниться в БД, то таблицу с пользователями секционируем по хэшу.

4. Какие процедуры необходимо выполнить для обеспечения устойчивости базы данных от потери данных в рамках одного датацентра?

В рамках одного датацентра необходимо чтобы были правильно настроены параметры БД относительно fsync, включены full_page_writes, а так же, если данные очень критичны  data_checksums. Был настроен отказоустойчивый кластер, постоянные бэкапы с выносом их на другую машину, а так же регламентом периодического восстановления, и мониторинг функционирования всех фаз обеспечения безопасности данных.
